# ğŸ§  Day 2 â€“ Manual ETL vs Pandas ETL

---

## ğŸ¯ Goal

Understand how to extract, transform, and load (ETL) structured data manually with core Python, then refactor the same workflow using **pandas** to achieve cleaner, faster, and more maintainable code.

---

## ğŸ§© Part A â€“ Manual File Handling ETL (Pre-pandas)

### **Objective**

Learn what ETL means by manually reading CSV & JSON, transforming the data, writing it back, and logging each step.

### **Core Concepts**

| Concept                         | Library            | Purpose                |
| ------------------------------- | ------------------ | ---------------------- |
| `csv.DictReader`, `json.load()` | Built-ins          | Parse structured files |
| `os`, `pathlib`                 | File system safety | Relative paths         |
| Custom `logger.py`              | `logging`          | Standardized logs      |
| List comprehension              | Python core        | Transform records      |

### **Simplified Flow**

1. **Extract** â†’ Read `users.csv` and `sales.json`.
2. **Transform** â†’ Add a new list of records with mock `sales_count = len(sales)` for each user.
3. **Load** â†’ Write to `data/output/transformed_data.csv`.
4. **Log** â†’ Write progress to `logs/app.log`.

### **Key Takeaways**

* You saw what â€œrawâ€ ETL code looks like (file I/O, loops, error handling).
* Great for understanding I/O flow, but verbose and fragile for real data.
* Every transformation had to be written manually.

---

## ğŸ§© Part B â€“ Pandas ETL Implementation (Actual Day 2 Task)

### **Objective**

Use `pandas` to handle the same ETL workflow declaratively and vectorized.

### **Pipeline**

1. **Extract**

   ```python
   df = pd.read_csv(input_path)
   ```
2. **Transform**

   ```python
   df["full_name"] = df["first_name"].str.strip() + " " + df["last_name"].str.strip()
   df.loc[df["department"] == "Engineering", "salary"] *= 1.10
   df = df.dropna()
   df["updated_at"] = pd.Timestamp.now()
   ```
3. **Load**

   ```python
   df.to_json(output_path, orient="records", indent=4)
   ```
4. **Verify**

   ```python
   pd.read_json(output_path)
   ```

### **Result Summary**

| Before Cleaning | After Cleaning | File Written To                     |
| --------------- | -------------- | ----------------------------------- |
| 5 rows          | 4 rows         | `data/output/employees_output.json` |

### **Benefits Observed**

| Manual Approach              | Pandas Approach                 |
| ---------------------------- | ------------------------------- |
| Custom read/write functions  | Built-in `read_csv` / `to_json` |
| Row-by-row loops             | Vectorized operations           |
| Manual type handling         | Automatic type inference        |
| Explicit string manipulation | `.str` accessor                 |
| Slow for large data          | Optimized C-level execution     |
| Multiple lines of code       | Few declarative statements      |

---

## âš™ï¸ Technical Details (Shared Infrastructure)

### Folder Structure

```
Day2_File_Operations_CSV_JSON_Handling/
â”‚
â”œâ”€â”€ etl_scripts/
â”‚   â”œâ”€â”€ file_handler.py        # manual ETL utilities
â”‚   â”œâ”€â”€ main_etl.py            # manual ETL runner
â”‚   â”œâ”€â”€ etl_employees.py       # pandas ETL script
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ logger.py              # shared logger
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/
â”‚   â”‚   â”œâ”€â”€ users.csv
â”‚   â”‚   â”œâ”€â”€ sales.json
â”‚   â”‚   â””â”€â”€ employees.csv
â”‚   â””â”€â”€ output/
â”‚       â”œâ”€â”€ transformed_data.csv
â”‚       â””â”€â”€ employees_output.json
â”‚
â””â”€â”€ logs/
    â””â”€â”€ app.log
```

---

## ğŸ§  Comparison & Learning Highlights

| Category            | Manual ETL (Pre-pandas)      | Pandas ETL                          |
| ------------------- | ---------------------------- | ----------------------------------- |
| **Ease of Coding**  | Verbose; loops & try/except  | Compact vectorized syntax           |
| **Performance**     | Pure Python looping â†’ slow   | C-optimized vectorization           |
| **Maintainability** | Hard to extend               | Easy to add new columns/filters     |
| **Scalability**     | Suitable only for tiny files | Handles millions of rows            |
| **Readability**     | Low â€“ imperative             | High â€“ declarative                  |
| **Logging**         | Manual                       | Still integrated via shared logger  |
| **Lesson Learned**  | Foundation of ETL            | Modern data transformation workflow |

---

## ğŸ§¾ Outcome

You built two versions of the same ETL process:

1. **Manual Core-Python ETL** â†’ learned how ETL works internally.
2. **Pandas ETL** â†’ learned how to do the same thing correctly and efficiently.

You now understand **what pandas is abstracting** and **why every data engineer uses it.**

---

## ğŸªµ Log Example

```
2025-11-11 12:12:25 - INFO - Reading input CSV...
2025-11-11 12:12:25 - INFO - Initial row count: 5
2025-11-11 12:12:25 - INFO - Row count after cleaning: 4
2025-11-11 12:12:25 - INFO - Wrote cleaned data to employees_output.json
```

---

## ğŸ”® Next Step â€“ Day 3 Preview

* Merge data sources with `pd.merge()`.
* Aggregate metrics using `groupby()`.
* Export multi-format outputs (CSV, JSON, Excel).
* Integrate basic validation checks.

---

## âœ… Commit Message

```
docs: Day 2 â€“ Manual ETL vs Pandas ETL comparison and learning summary
```

---

## ğŸ—’ Notion Layout Suggestion

| Section                   | Content                                                                                               |
| ------------------------- | ----------------------------------------------------------------------------------------------------- |
| **Title**                 | Day 2 â€“ Manual ETL vs Pandas ETL                                                                      |
| **Goal**                  | Understand ETL fundamentals by building a manual pipeline, then optimize with pandas.                 |
| **Manual ETL Highlights** | File I/O, loops, logging, CSV/JSON modules                                                            |
| **Pandas ETL Highlights** | `read_csv`, `loc`, `dropna`, `to_json`, timestamp                                                     |
| **Comparison Table**      | (copy from above)                                                                                     |
| **Key Takeaway**          | Pandas abstracts away low-level file handling and loops into expressive, high-performance operations. |
| **Next Focus**            | Groupby and merging data sets for aggregations.                                                       |

---

This combined doc shows your growth curve: from *manual control* to *data-engineering maturity*.